{"cells":[{"cell_type":"markdown","metadata":{"id":"Za8-Nr5k11fh"},"source":["##### Copyright 2018 The TensorFlow Authors."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Eq10uEbw0E4l"},"outputs":[],"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"oYM61xrTsP5d"},"source":["# Transfer Learning with TensorFlow Hub for TFLite"]},{"cell_type":"markdown","metadata":{"id":"aFNhz34Svuhe"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c02_transfer_learning.ipynb\">\n","    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n","    Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c02_transfer_learning.ipynb\">\n","    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n","    View source on GitHub</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"bL54LWCHt5q5"},"source":["## Setup"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3943,"status":"ok","timestamp":1708004910064,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"dlauq-4FWGZM","outputId":"4c3e3d82-1697-44d2-c2c8-4c9b290e420e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Version:  2.16.0-dev20240209\n","GPU is NOT AVAILABLE\n"]}],"source":["import os\n","\n","import matplotlib.pylab as plt\n","import numpy as np\n","\n","import tensorflow as tf\n","\n","\n","print(\"Version: \", tf.__version__)\n","\n","print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":607,"status":"ok","timestamp":1708004925468,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"0a-oZviOBqDQ"},"outputs":[],"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","   for gpu in gpus:\n","      tf.config.experimental.set_memory_growth(gpu, True)"]},{"cell_type":"markdown","metadata":{"id":"mmaHHH7Pvmth"},"source":["## Select the Hub/TF2 module to use\n","\n","Hub modules for TF 1.x won't work here, please use one of the selections provided."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708004930285,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"FlsEcKVeuCnf","outputId":"1372dd0d-ed16-4b69-ea72-169dfd46034d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n"]}],"source":["module_selection = (\"mobilenet_v2\", 224, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n","handle_base, pixels, FV_SIZE = module_selection\n","MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n","IMAGE_SIZE = (pixels, pixels)\n","print(\"Using {} with input size {} and output dimension {}\".format(\n","  MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"]},{"cell_type":"markdown","metadata":{"id":"sYUsgwCBv87A"},"source":["## Data preprocessing"]},{"cell_type":"markdown","metadata":{"id":"8nqVX3KYwGPh"},"source":["Use [TensorFlow Datasets](http://tensorflow.org/datasets) to load the cats and dogs dataset.\n","\n","This `tfds` package is the easiest way to load pre-defined data. If you have your own data, and are interested in importing using it with TensorFlow see [loading image data](../load_data/images.ipynb)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3829,"status":"ok","timestamp":1708004986577,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"gQIMY7Qd97TF","outputId":"d6703ccc-ace3-4724-d807-a9196eb33c09"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jGvpkDj4wBup"},"outputs":[],"source":["import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708004991040,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"YLzTR_iw-hlr"},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator\n","def grayscale_conversion(image):\n","    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    # Repeat the single channel across three channels\n","    grayscale_image = np.stack((grayscale_image,) * 3, axis=-1)\n","    return grayscale_image\n","normal_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255,\n",")\n","noisy_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255,\n","    preprocessing_function=lambda x: x + np.random.normal(0, 0.1, x.shape),  # Add noise\n",")\n","shaded_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255,\n","    brightness_range=[0.5, 1.5],  # Adjust the range for shading\n",")\n","grayscale_datagen = ImageDataGenerator(\n","    preprocessing_function= grayscale_conversion,\n","    rescale=1.0 / 255,\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":515,"status":"ok","timestamp":1708005136550,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"eQyA7uuJ-6CK"},"outputs":[],"source":["train_data_dir='/content/drive/MyDrive/Split/train'\n","img_size=pixels\n","batch_size=32"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1245,"status":"ok","timestamp":1708005139859,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"RCjNaRgW-eyM","outputId":"fa26e7ab-2548-4059-b3bb-06232650c8cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 8410 images belonging to 5 classes.\n","Found 8410 images belonging to 5 classes.\n","Found 8410 images belonging to 5 classes.\n","Found 8410 images belonging to 5 classes.\n"]}],"source":["generator1 = normal_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_size,img_size),\n","    batch_size=batch_size,\n","    shuffle=True,\n","    seed=41,\n","    class_mode='categorical'\n",")\n","generator2 = shaded_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_size,img_size),\n","    batch_size=batch_size,\n","    shuffle=True,\n","    seed=42,\n","    class_mode='categorical'\n",")\n","generator3 = noisy_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_size,img_size),\n","    batch_size=batch_size,\n","    shuffle=True,\n","    seed=43,\n","    class_mode='categorical'\n",")\n","generator4 = grayscale_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_size,img_size),\n","    batch_size=batch_size,\n","    shuffle=True,\n","    seed=44,\n","    class_mode='categorical'\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":471,"status":"ok","timestamp":1708005021374,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"pWjsDwR7_kws"},"outputs":[],"source":["from keras.utils import Sequence\n","class MergedGenerators(Sequence):\n","    def __init__(self, generators):\n","        self.generators = generators\n","        self.lengths = [len(gen) for gen in generators]\n","        self.cumulative_lengths = np.cumsum(self.lengths)\n","\n","    def __len__(self):\n","        return self.cumulative_lengths[-1]\n","\n","    def __getitem__(self, index):\n","        generator_index = np.argmax(index < self.cumulative_lengths)\n","        if generator_index > 0:\n","            sample_index = index - self.cumulative_lengths[generator_index - 1]\n","        else:\n","            sample_index = index\n","\n","        # Get the data and labels from the corresponding generator\n","        data, labels = self.generators[generator_index][sample_index]\n","        return data, labels"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1708005145858,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"9JUsX7Hj_n-2"},"outputs":[],"source":["combined_generator = MergedGenerators([generator1, generator2, generator3, generator4])"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1708005147592,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"tHpSiani_1KV","outputId":"1048406d-13d4-40ea-ccc4-180cedb09e8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2400 images belonging to 5 classes.\n"]}],"source":["test_data_dir='/content/drive/MyDrive/Split/val'\n","test_datagen = ImageDataGenerator(rescale = 1.0/255)\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_data_dir,\n","    target_size=(img_size, img_size),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B9DEQ1cc_1N5"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ghQhZjgEw1cK"},"source":["Inspect a batch"]},{"cell_type":"markdown","metadata":{"id":"FS_gVStowW3G"},"source":["## Defining the model\n","\n","All it takes is to put a linear classifier on top of the `feature_extractor_layer` with the Hub module.\n","\n","For speed, we start out with a non-trainable `feature_extractor_layer`, but you can also enable fine-tuning for greater accuracy."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1708005042651,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"RaJW3XrPyFiF"},"outputs":[],"source":["do_fine_tuning = False #@param {type:\"boolean\"}"]},{"cell_type":"markdown","metadata":{"id":"wd0KfstqaUmE"},"source":["Load TFHub Module"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1727,"status":"ok","timestamp":1708005067520,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"svvDrt3WUrrm"},"outputs":[],"source":["feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n","                                   input_shape=IMAGE_SIZE + (3,),\n","                                   output_shape=[FV_SIZE],\n","                                   trainable=do_fine_tuning)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1271,"status":"ok","timestamp":1708005070519,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"50FYNIb1dmJH","outputId":"8b2e6198-c7fe-4233-82fc-75b3d74da16b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Building model with https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," keras_layer_1 (KerasLayer)  (None, 1280)              2257984   \n","                                                                 \n"," dense (Dense)               (None, 5)                 6405      \n","                                                                 \n","=================================================================\n","Total params: 2264389 (8.64 MB)\n","Trainable params: 6405 (25.02 KB)\n","Non-trainable params: 2257984 (8.61 MB)\n","_________________________________________________________________\n"]}],"source":["print(\"Building model with\", MODULE_HANDLE)\n","model = tf.keras.Sequential([\n","    feature_extractor,\n","    tf.keras.layers.Dense(5)\n","])\n","model.summary()"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":484,"status":"ok","timestamp":1708005075877,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"1PzLoQK0Zadv"},"outputs":[],"source":["#@title (Optional) Unfreeze some layers\n","NUM_LAYERS = 7 #@param {type:\"slider\", min:1, max:50, step:1}\n","\n","if do_fine_tuning:\n","  feature_extractor.trainable = True\n","\n","  for layer in model.layers[-NUM_LAYERS:]:\n","    layer.trainable = True\n","\n","else:\n","  feature_extractor.trainable = False"]},{"cell_type":"markdown","metadata":{"id":"u2e5WupIw2N2"},"source":["## Training the model"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":484,"status":"ok","timestamp":1708005297498,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"9f3yBUvkd_VJ"},"outputs":[],"source":["if do_fine_tuning:\n","  model.compile(\n","    optimizer=tf.keras.optimizers.SGD(lr=0.002, momentum=0.9),\n","    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","    metrics=['accuracy'])\n","else:\n","  model.compile(\n","    optimizer='adam',\n","    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","    metrics=['accuracy'])"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"elapsed":106596,"status":"error","timestamp":1708005440762,"user":{"displayName":"","userId":""},"user_tz":-345},"id":"w_YKX2Qnfg6x","outputId":"7c74cf57-b660-4c95-cca4-4b4e25a6fd46"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","  12/1052 [..............................] - ETA: 2:17:18 - loss: 1.6164 - accuracy: 0.2708"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-237499773ac3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m hist = model.fit(combined_generator,\n\u001b[0m\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     validation_data=test_generator)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import cv2\n","EPOCHS = 10\n","hist = model.fit(combined_generator,\n","                    epochs=EPOCHS,\n","                    validation_data=test_generator)"]},{"cell_type":"markdown","metadata":{"id":"u_psFoTeLpHU"},"source":["## Export the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XaSb5nVzHcVv"},"outputs":[],"source":["CATS_VS_DOGS_SAVED_MODEL = \"exp_saved_model\""]},{"cell_type":"markdown","metadata":{"id":"fZqRAg1uz1Nu"},"source":["Export the SavedModel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJMue5YgnwtN"},"outputs":[],"source":["tf.saved_model.save(model, CATS_VS_DOGS_SAVED_MODEL)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SOQF4cOan0SY"},"outputs":[],"source":["%%bash -s $CATS_VS_DOGS_SAVED_MODEL\n","saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FY7QGBgBytwX"},"outputs":[],"source":["loaded = tf.saved_model.load(CATS_VS_DOGS_SAVED_MODEL)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tIhPyMISz952"},"outputs":[],"source":["print(list(loaded.signatures.keys()))\n","infer = loaded.signatures[\"serving_default\"]\n","print(infer.structured_input_signature)\n","print(infer.structured_outputs)"]},{"cell_type":"markdown","metadata":{"id":"XxLiLC8n0H16"},"source":["## Convert using TFLite's Converter"]},{"cell_type":"markdown","metadata":{"id":"1aUYvCpfWmrQ"},"source":["Load the TFLiteConverter with the SavedModel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dqJRyIg8Wl1n"},"outputs":[],"source":["converter = tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)"]},{"cell_type":"markdown","metadata":{"id":"AudcNjT0UtfF"},"source":["### Post-training quantization\n","The simplest form of post-training quantization quantizes weights from floating point to 8-bits of precision. This technique is enabled as an option in the TensorFlow Lite converter. At inference, weights are converted from 8-bits of precision to floating point and computed using floating-point kernels. This conversion is done once and cached to reduce latency.\n","\n","To further improve latency, hybrid operators dynamically quantize activations to 8-bits and perform computations with 8-bit weights and activations. This optimization provides latencies close to fully fixed-point inference. However, the outputs are still stored using floating point, so that the speedup with hybrid ops is less than a full fixed-point computation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WmSr2-yZoUhz"},"outputs":[],"source":["converter.optimizations = [tf.lite.Optimize.DEFAULT]"]},{"cell_type":"markdown","metadata":{"id":"YpCijI08UxP0"},"source":["### Post-training integer quantization\n","We can get further latency improvements, reductions in peak memory usage, and access to integer only hardware accelerators by making sure all model math is quantized. To do this, we need to measure the dynamic range of activations and inputs with a representative data set. You can simply create an input data generator and provide it to our converter."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"clM_dTIkWdIa"},"outputs":[],"source":["def representative_data_gen():\n","  for input_value, _ in test_batches.take(100):\n","    yield [input_value]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0oPkAxDvUias"},"outputs":[],"source":["converter.representative_dataset = representative_data_gen"]},{"cell_type":"markdown","metadata":{"id":"IGUAVTqXVfnu"},"source":["The resulting model will be fully quantized but still take float input and output for convenience.\n","\n","Ops that do not have quantized implementations will automatically be left in floating point. This allows conversion to occur smoothly but may restrict deployment to accelerators that support float."]},{"cell_type":"markdown","metadata":{"id":"cPVdjaEJVkHy"},"source":["### Full integer quantization\n","\n","To require the converter to only output integer operations, one can specify:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eQi1aO2cVhoL"},"outputs":[],"source":["converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]"]},{"cell_type":"markdown","metadata":{"id":"snwssESbVtFw"},"source":["### Finally convert the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUEgr46WVsqd"},"outputs":[],"source":["tflite_model = converter.convert()\n","tflite_model_file = 'converted_model.tflite'\n","\n","with open(tflite_model_file, \"wb\") as f:\n","  f.write(tflite_model)"]},{"cell_type":"markdown","metadata":{"id":"BbTF6nd1KG2o"},"source":["##Test the TFLite model using the Python Interpreter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dg2NkVTmLUdJ"},"outputs":[],"source":["# Load TFLite model and allocate tensors.\n","\n","interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n","interpreter.allocate_tensors()\n","\n","input_index = interpreter.get_input_details()[0][\"index\"]\n","output_index = interpreter.get_output_details()[0][\"index\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snJQVs9JNglv"},"outputs":[],"source":["from tqdm import tqdm\n","\n","# Gather results for the randomly sampled test images\n","predictions = []\n","\n","test_labels, test_imgs = [], []\n","for img, label in tqdm(test_batches.take(10)):\n","  interpreter.set_tensor(input_index, img)\n","  interpreter.invoke()\n","  predictions.append(interpreter.get_tensor(output_index))\n","\n","  test_labels.append(label.numpy()[0])\n","  test_imgs.append(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"YMTWNqPpNiAI"},"outputs":[],"source":["#@title Utility functions for plotting\n","# Utilities for plotting\n","\n","class_names = ['cat', 'dog']\n","\n","def plot_image(i, predictions_array, true_label, img):\n","  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","\n","  img = np.squeeze(img)\n","\n","  plt.imshow(img, cmap=plt.cm.binary)\n","\n","  predicted_label = np.argmax(predictions_array)\n","  if predicted_label == true_label:\n","    color = 'green'\n","  else:\n","    color = 'red'\n","\n","  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n","                                100*np.max(predictions_array),\n","                                class_names[true_label]),\n","                                color=color)\n"]},{"cell_type":"markdown","metadata":{"id":"fK_CTyL3XQt1"},"source":["NOTE: Colab runs on server CPUs. At the time of writing this, TensorFlow Lite doesn't have super optimized server CPU kernels. For this reason post-training full-integer quantized models  may be slower here than the other kinds of optimized models. But for mobile CPUs, considerable speedup can be observed."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"1-lbnicPNkZs"},"outputs":[],"source":["#@title Visualize the outputs { run: \"auto\" }\n","index = 0 #@param {type:\"slider\", min:0, max:9, step:1}\n","plt.figure(figsize=(6,3))\n","plt.subplot(1,2,1)\n","plot_image(index, predictions, test_labels, test_imgs)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"PmZRieHmKLY5"},"source":["Download the model.\n","\n","**NOTE: You might have to run to the cell below twice**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0jJAxrQB2VFw"},"outputs":[],"source":["labels = ['cat', 'dog']\n","\n","with open('labels.txt', 'w') as f:\n","  f.write('\\n'.join(labels))\n","\n","try:\n","  from google.colab import files\n","  files.download('converted_model.tflite')\n","  files.download('labels.txt')\n","except:\n","  pass"]},{"cell_type":"markdown","metadata":{"id":"BDlmpjC6VnFZ"},"source":["# Prepare the test images for download (Optional)"]},{"cell_type":"markdown","metadata":{"id":"_1ja_WA0WZOH"},"source":["This part involves downloading additional test images for the Mobile Apps only in case you need to try out more samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fzLKEBrfTREA"},"outputs":[],"source":["!mkdir -p test_images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qn7ukNQCSewb"},"outputs":[],"source":["from PIL import Image\n","\n","for index, (image, label) in enumerate(test_batches.take(50)):\n","  image = tf.cast(image * 255.0, tf.uint8)\n","  image = tf.squeeze(image).numpy()\n","  pil_image = Image.fromarray(image)\n","  pil_image.save('test_images/{}_{}.jpg'.format(class_names[label[0]], index))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xVKKWUG8UMO5"},"outputs":[],"source":["!ls test_images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_w_-UdlS9Vi"},"outputs":[],"source":["!zip -qq cats_vs_dogs_test_images.zip -r test_images/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Giva6EHwWm6Y"},"outputs":[],"source":["try:\n","  files.download('cats_vs_dogs_test_images.zip')\n","except:\n","  pass"]}],"metadata":{"accelerator":"GPU","colab":{"name":"tflite_c02_transfer_learning.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c02_transfer_learning.ipynb","timestamp":1708005452140}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
